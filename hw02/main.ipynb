{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "\n",
    "def download_mnist(is_train: bool):\n",
    "    dataset = MNIST(\n",
    "        root=\"./data\",\n",
    "        transform=lambda x: np.array(x).flatten(),\n",
    "        download=True,\n",
    "        train=is_train,\n",
    "    )\n",
    "\n",
    "    mnist_data = []\n",
    "    mnist_labels = []\n",
    "\n",
    "    for image, label in dataset:\n",
    "        mnist_data.append(image)\n",
    "        mnist_labels.append([int(i == label) for i in range(10)])\n",
    "\n",
    "    return mnist_data, mnist_labels\n",
    "\n",
    "\n",
    "train_X, train_Y = download_mnist(True)\n",
    "test_X, test_Y = download_mnist(False)\n",
    "\n",
    "# normalize data\n",
    "train_X = np.divide(np.array(train_X, dtype=np.float128), 255)\n",
    "test_X = np.divide(np.array(test_X, dtype=np.float128), 255)\n",
    "\n",
    "trainset_size = len(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_rate = 0.001\n",
    "epochs = 50\n",
    "running = True\n",
    "\n",
    "batch_size = 100\n",
    "image_size = 784\n",
    "output_size = 10\n",
    "\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "\n",
    "def softmax(weighted_sum):\n",
    "    powed = np.power(np.e, weighted_sum, dtype=np.float128)\n",
    "    return np.divide(powed, powed.sum())\n",
    "\n",
    "\n",
    "def cross_entropy(prob, target):\n",
    "    return np.negative(target).dot(np.log2(prob, dtype=np.float128))\n",
    "\n",
    "\n",
    "# def train(trainset, labels, weights, bias):\n",
    "#     # iterative version\n",
    "#     global learn_rate\n",
    "\n",
    "#     w = np.zeros((image_size, output_size), dtype=np.float128)\n",
    "#     b = np.zeros((output_size), dtype=np.float128)\n",
    "\n",
    "#     for input, label in zip(trainset, labels):\n",
    "#         classification = softmax(input.dot(weights) + bias)\n",
    "#         error = label - classification\n",
    "\n",
    "#         w += learn_rate * np.atleast_2d(input).T.dot(np.atleast_2d(error))\n",
    "#         b += learn_rate * error\n",
    "\n",
    "#     return w, b\n",
    "\n",
    "\n",
    "def train(trainset, labels, weights, bias):\n",
    "    # math version\n",
    "    global learn_rate\n",
    "\n",
    "    weighted_sums = trainset.dot(weights) + bias\n",
    "    classification = np.array([softmax(weighted_sum) for weighted_sum in weighted_sums])\n",
    "    error = learn_rate * (labels - classification)\n",
    "\n",
    "    return trainset.T.dot(error), sum(error)\n",
    "\n",
    "\n",
    "w = np.zeros((image_size, output_size), dtype=np.float128)\n",
    "b = np.zeros((output_size), dtype=np.float128)\n",
    "\n",
    "while epochs > 0:\n",
    "    # shuffle data\n",
    "    train_zipped = list(zip(train_X, train_Y))\n",
    "    np.random.shuffle(train_zipped)\n",
    "    train_X, train_Y = list(zip(*train_zipped))\n",
    "\n",
    "    for trainset, labels in zip(\n",
    "        np.array_split(train_X, trainset_size // batch_size),\n",
    "        np.array_split(train_Y, trainset_size // batch_size),\n",
    "    ):\n",
    "        dw, db = train(trainset, labels, w, b)\n",
    "\n",
    "        w += dw\n",
    "        b += db\n",
    "\n",
    "    epochs -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 9247 / 10000 correct answers\n",
      "0.9247\n"
     ]
    }
   ],
   "source": [
    "def softmax(weighted_sum):\n",
    "    powed = np.power(np.e, weighted_sum, dtype=np.float128)\n",
    "    return np.divide(powed, powed.sum())\n",
    "\n",
    "def test(testset, labels, weights, bias):\n",
    "    correct = 0\n",
    "\n",
    "    for input, label in zip(testset, labels):\n",
    "        classification = softmax(input.dot(weights) + bias)\n",
    "\n",
    "        if label[classification.argmax()] == 1:\n",
    "            correct += 1\n",
    "\n",
    "    print(f\"Got {correct} / {len(testset)} correct answers\")\n",
    "    return correct / len(testset)\n",
    "\n",
    "\n",
    "print(test(test_X, test_Y, w, b))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
